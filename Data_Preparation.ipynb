{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This notebook serves the purpose of loading the data from the datasets folder. The datasets for detection and recognition are German Traffic Sign Detection Benchmark (GTSDB) and the German Traffic Sign Recognition Benchmark (GTSRB) used in the online competition by IEEE International Joint Conference on Neural Networks.\n",
    "\n",
    "## Recognition Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage import io,color, exposure, transform\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "#### Function for loading images from folder recursively\n",
    "Images are cropped according to bounding boxes and resized to 32x32 to maintain uniformity in image sizes. Because of the recursive nature it goes into all the directories and loads the images. The bounding boxes are provided by the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "row=0\n",
    "\n",
    "def load_images_from_folder(folder,df):\n",
    "    global row\n",
    "    for filename in os.listdir(folder):\n",
    "        if os.path.isdir(os.path.join(folder,filename)):\n",
    "            load_images_from_folder(os.path.join(folder,filename),df)\n",
    "        if os.path.isdir(os.path.join(folder,filename)) == False and filename[-3:] == 'ppm':\n",
    "            img = io.imread(os.path.join(folder,filename),as_grey=False)\n",
    "            if img is not None:\n",
    "                cropped_image = crop_the_image(img,df,row)\n",
    "                resized_cropped_image = cv2.resize(cropped_image,(32,32))\n",
    "                images.append(resized_cropped_image)\n",
    "                row=row+1\n",
    "\n",
    "            if len(images)%1000==0:\n",
    "                print str(len(images))+' images loaded.'\n",
    "\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for cropping the images according to the bounding boxes\n",
    "\n",
    "**Roi.X1** is the lower x coordinate.\n",
    "\n",
    "**Roi.X2** is the higher x coordinate\n",
    "\n",
    "**Roi.Y1** is the lower y coordinate\n",
    "\n",
    "**Roi.Y2** is the higher y coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_the_image(image,df,i):\n",
    "    x1=df.loc[i]['Roi.X1']\n",
    "    y1=df.loc[i]['Roi.Y1']\n",
    "    x2=df.loc[i]['Roi.X2']\n",
    "    y2=df.loc[i]['Roi.Y2']\n",
    "    img = image[y1:y2,x1:x2]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for getting dataframe of bounding boxes\n",
    "\n",
    "The bounding boxes for each of the sign class is specified in a separate csv file. Hence, all of them are loaded and concatenated into a single, large dataframe called **df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_df_from_csv(train=True,detect=False):\n",
    "    if detect==False:\n",
    "        if train == True:\n",
    "            df=pd.read_csv('datasets/GTSRB/Final_Training/Images/00000/GT-00000.csv')\n",
    "            for i in xrange(1,43):\n",
    "                if i < 10:\n",
    "                    df2=pd.read_csv('datasets/GTSRB/Final_Training/Images/0000'+str(i)+'/GT-0000'+str(i)+'.csv')\n",
    "                else:\n",
    "                    df2=pd.read_csv('datasets/GTSRB/Final_Training/Images/000'+str(i)+'/GT-000'+str(i)+'.csv')\n",
    "                df3=[df,df2]\n",
    "                df=pd.concat(df3,ignore_index=True)\n",
    "        else:\n",
    "            df = pd.read_csv('datasets/GTSRB_Test/Final_Test/Images/GT-final_test.test.csv')\n",
    "    else:\n",
    "        df=pd.read_csv('datasets/FullIJCNN2013/gt_csv.csv')\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got CSV files\n",
      "1000 images loaded.\n",
      "2000 images loaded.\n",
      "3000 images loaded.\n",
      "4000 images loaded.\n",
      "5000 images loaded.\n",
      "6000 images loaded.\n",
      "7000 images loaded.\n",
      "8000 images loaded.\n",
      "9000 images loaded.\n",
      "10000 images loaded.\n",
      "11000 images loaded.\n",
      "12000 images loaded.\n",
      "13000 images loaded.\n",
      "14000 images loaded.\n",
      "15000 images loaded.\n",
      "16000 images loaded.\n",
      "17000 images loaded.\n",
      "18000 images loaded.\n",
      "19000 images loaded.\n",
      "20000 images loaded.\n",
      "21000 images loaded.\n",
      "22000 images loaded.\n",
      "23000 images loaded.\n",
      "24000 images loaded.\n",
      "25000 images loaded.\n",
      "26000 images loaded.\n",
      "27000 images loaded.\n",
      "28000 images loaded.\n",
      "29000 images loaded.\n",
      "30000 images loaded.\n",
      "31000 images loaded.\n",
      "32000 images loaded.\n",
      "33000 images loaded.\n",
      "34000 images loaded.\n",
      "35000 images loaded.\n",
      "36000 images loaded.\n",
      "37000 images loaded.\n",
      "38000 images loaded.\n",
      "39000 images loaded.\n",
      "\n",
      "Finished loading training data.\n",
      "==============================================\n",
      "1000 images loaded.\n",
      "2000 images loaded.\n",
      "3000 images loaded.\n",
      "4000 images loaded.\n",
      "5000 images loaded.\n",
      "6000 images loaded.\n",
      "7000 images loaded.\n",
      "8000 images loaded.\n",
      "9000 images loaded.\n",
      "10000 images loaded.\n",
      "11000 images loaded.\n",
      "12000 images loaded.\n",
      "\n",
      "Finished loading testing data.\n"
     ]
    }
   ],
   "source": [
    "global row\n",
    "\n",
    "bounding_box_df = get_df_from_csv()\n",
    "print \"Got CSV files\"\n",
    "d = load_images_from_folder('datasets/GTSRB',bounding_box_df)\n",
    "data = numpy.array(d)\n",
    "labels = numpy.array(bounding_box_df['ClassId'])\n",
    "print ''\n",
    "print \"Finished loading training data.\"\n",
    "print \"==============================================\"\n",
    "del images[:]\n",
    "row = 0\n",
    "\n",
    "test_bounding_box_df = get_df_from_csv(train=False)\n",
    "test_d = load_images_from_folder('datasets/GTSRB_Test',test_bounding_box_df)\n",
    "test_data = numpy.array(test_d)\n",
    "\n",
    "print ''\n",
    "print \"Finished loading testing data.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Data Successfully\n"
     ]
    }
   ],
   "source": [
    "numpy.save('storage/data_file.npy',data)\n",
    "numpy.save('storage/labels_file.npy',labels)\n",
    "numpy.save('storage/test_data_file.npy',test_data)\n",
    "\n",
    "print \"Saved Data Successfully\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "#### Function for loading images from folder recursively\n",
    "\n",
    "The images are loaded recursively from the dataset folder. They also cropped and positive and negative samples are extracted from them simultaneously. As some images have more than one traffic sign in the image, a while loop is used to ensure all the signs are cropped and saved as positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "row=0\n",
    "sign_labels = []\n",
    "\n",
    "def load_detect_images_from_folder(folder,df):\n",
    "    global row\n",
    "\n",
    "\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if os.path.isdir(os.path.join(folder,filename)):\n",
    "            load_images_from_folder(os.path.join(folder,filename),df)\n",
    "        if os.path.isdir(os.path.join(folder,filename)) == False and filename[-3:] == 'ppm':\n",
    "            img = io.imread(os.path.join(folder,filename),as_grey=False)\n",
    "            if img is not None and (filename==df.loc[row]['Filename']):\n",
    "\n",
    "                if row < 1212:\n",
    "                    if df.loc[row]['Filename'] == df.loc[row+1]['Filename']:\n",
    "                        while True:\n",
    "                            cropped_image= positive_example(img,df,row)\n",
    "                            resized_cropped_image = cv2.resize(cropped_image,(32,32))\n",
    "                            images.append(resized_cropped_image)\n",
    "                            sign_labels.append(1)\n",
    "                            negative_images = negative_examples(img,df,row)\n",
    "                            for i in negative_images:\n",
    "                                images.append(i)\n",
    "                            for i in range(6):\n",
    "                                sign_labels.append(0)\n",
    "\n",
    "                            if df.loc[row]['Filename'] != df.loc[row+1]['Filename']:\n",
    "                                row=row+1\n",
    "                                break\n",
    "                            row=row+1\n",
    "                    else:\n",
    "                        cropped_image= positive_example(img,df,row)\n",
    "                        resized_cropped_image = cv2.resize(cropped_image,(32,32))\n",
    "                        images.append(resized_cropped_image)\n",
    "                        sign_labels.append(1)\n",
    "                        negative_images = negative_examples(img,df,row)\n",
    "                        for i in negative_images:\n",
    "                            images.append(i)\n",
    "                        for i in range(6):\n",
    "                            sign_labels.append(0)\n",
    "                        row=row+1\n",
    "\n",
    "\n",
    "    return (images,sign_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for generating positive and negative examples\n",
    "\n",
    "Positive samples are just extracted by simple cropping the image according to the bounding boxes. Negative samples are taken in a different method. Random numbers within the image size limits are generated in the **generate(limit,low,high)** function. Care is taken to avoid taking the same numbers as the one in the bounding boxes. These random numbers specify the coordinates using which random patches of the image are cropped to be used as negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def positive_example(image,df,i):\n",
    "    x1=df.loc[i]['Roi.X1']\n",
    "    y1=df.loc[i]['Roi.Y1']\n",
    "    x2=df.loc[i]['Roi.X2']\n",
    "    y2=df.loc[i]['Roi.Y2']\n",
    "    return image[y1:y2,x1:x2]\n",
    "\n",
    "def negative_examples(image,df,i):\n",
    "    x1=df.loc[i]['Roi.X1']\n",
    "    y1=df.loc[i]['Roi.Y1']\n",
    "    x2=df.loc[i]['Roi.X2']\n",
    "    y2=df.loc[i]['Roi.Y2']\n",
    "    rx = generate(image.shape[1],x1,x2)\n",
    "    ry = generate(image.shape[0],y1,y2)\n",
    "    img_arr = []\n",
    "    for i,j in zip(rx,ry):\n",
    "        img_arr.append(image[j:j+32,i:i+32])\n",
    "    return img_arr\n",
    "\n",
    "def generate(limit,low,high):\n",
    "    numbers = []\n",
    "    for j in range(6):\n",
    "        i = low\n",
    "        while i<=high and i>=low:\n",
    "            i = random.randint(0,limit-32)\n",
    "        numbers.append(i)\n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got CSV files\n",
      "Finished loading detection data.\n",
      "Saved Data Successfully\n"
     ]
    }
   ],
   "source": [
    "bounding_box_df = get_df_from_csv(detect=True)\n",
    "print \"Got CSV files\"\n",
    "d,labels = load_detect_images_from_folder('datasets/FullIJCNN2013',bounding_box_df)\n",
    "data = numpy.array(d)\n",
    "classes = numpy.array(bounding_box_df['ClassId'])\n",
    "\n",
    "print \"Finished loading detection data.\"\n",
    "\n",
    "numpy.save('storage/detect_data_file.npy',data)\n",
    "numpy.save('storage/detect_labels_file.npy',labels)\n",
    "numpy.save('storage/detect_classes_file.npy',classes)\n",
    "\n",
    "\n",
    "print \"Saved Data Successfully\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
